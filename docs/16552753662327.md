# 一、OpenGL ES 概览
OpenGL 定义了一系列接口，约定GPU绘制的标准，具体实现由各电脑厂商实现。
它通过GPU计算得到一张图片，这张图片在内存中其实就是一块buffer，存储每个点的颜色信息

## EGL
这张图片最终是要显示到屏幕上,所以还需要具体的窗口系统来操作,OpenGL ES 并没有相关的函数。所以,OpenGL ES 有一个好搭档 EGL。
EGL,全称:embedded Graphic Interface,是 OpenGL ES 和底层 Native 平台 视窗系统之间的接口。
**EGL 是用于与手机设备打交道,比如获取绘制 buffer,将绘制 buffer 展现到手机屏幕中**。那么抛开 EGL 不说,OpenGL ES 与 GLSL 的主要功能,就是往这块 buffer 上绘制图片。

大致流程：
EGL获取屏幕的handle，根据屏幕分辨率创建buffer和用于存放OpenGL状态集的context，并将他们enable起来，OpenGL操作GPU将结果保存到buffer中，最后由EGL将绘制的内容显示到屏幕上

## OpenGL 工作流程
![截屏2022-10-22 14.45.18](media/16552753662327/%E6%88%AA%E5%B1%8F2022-10-22%2014.45.18.png)

1.经过VS计算得到最终的顶点信息
2.把算出来的顶点进行图元装配，构建虚拟的三角形和线
3.光栅化将虚拟的三角形和线包围区域栅格化，每一个栅格对应一个像素。[百度百科光栅化](https://baike.baidu.com/item/%25E5%2585%2589%25E6%25A0%2585%25E5%258C%2596?fromModule=lemma_search-box)
4.光珊化的结果传入 PS,进行最终的颜色计算
5.所谓最终的结果在被实际存储到绘制 buffer 之前,还需要进行一系列的操作。这些操作可能会修改甚至丢弃这些像素点。这些操作主要为 alpha test、Depth/Stencil test、Blend、Dither

手机屏幕上显示的图片,是由这上百万个像素点,以及这上百万个像素点对应的颜色组成的。
假如手机支持 Depth/stencil。那么通过 EGL 获取的绘制 buffer 中,每个像素点就包含了 RGBA 的颜色值,depth 值和 stencil 值,其中 RGBA 每个分量一般占据 8 位,也就是 8bit,也就是 1byte,而 depth 大多数占 24 位,stencil 占 8 位。所以每个像素占 64bit,也就是 8byte。那么 iphone6 plus 的绘制 buffer 的尺寸为 1920×1080×8=16588800byte=16200KB=15.8MB

## 总结
总结一下,经过 VS 和 PS 之后,程序员想要画的东西,就已经被画出来了。想要绘制的东西,也就是左下角图五的样子。然后再根据 OpenGL ES 的设置,对新绘制出来的东西进行 Depth/Stencil Test,剔除掉被遮挡的部分,将剩余部分与原图片进行 Blend,生成新的图片。 最后,通过 EGL,把这个生成的棋盘 buffer 和手机屏幕上对应的棋盘 buffer 进行调换,让手机屏幕显示这个新生成的棋盘,旧的那个棋盘再去绘制新的图片信息。周而复始,不停的把棋盘进行切换,也就像过去看连环画一样,动画就是由一幅幅的图片组成,当每秒切换的图片数量超过 30 张的时候,我们的手机也就看到了动态的效果。这就是屏幕上图片的产生过程

# 二、EGL 详解
 EGL 是绘制 API(比如 OpenGL ES)与 底层平台窗口系统之间的接口,用于与手机设备打交道,比如获取绘制 buffer。 而 OpenGL ES 与 GLSL 的主要功能,就是往这块 buffer 上绘制图片。由于绘制的第一步就是获取绘制 buffer,而这完全通过 EGL 来实现的,那么这一节,我们来仔细研究一下,EGL 是如何跟手机产生关联,并如何从手机那里获取一块 buffer 用于绘制

## EGL 总览
### 获取配置 
所谓的配置信息,就是手机支持多少种格式的绘制 buffer,每种格式对应着的 RGBA 是如何划分的,以及是否支持 depth、stencil 等

>EGL生成surface，它包含buffer，buffer又分为color buffer/depth buffer/stencil buffer。 EGL 生成的绘制 buffer 终归还是要提供给 OpenGL ES 使用

当我们知道了手机支持什么样格式的绘制 buffer 之后,就要根据我们所写的图形程序的需要,去对这些格式进行筛选,找到一个能满足我们需求,且手机支持的格式,然后通过 EGL 生成一块该格式的绘制 buffer。生成绘制 buffer 的过程,其实是我们通过 API 生成一块 surface,surface 是一个抽象概念,但是这个 surface 包含了绘制 buffer,假如我们所选择的格式是支持 RGBA、depth、stencil 的。那 么 surface 对应的绘制 buffer 有一块 Color buffer,到时候会用于保存图片的颜色信息,保存的方式在上一节我们做过介绍,就是 buffer 会对应上百万个像素点, 每个像素点有自己的颜色值,将这些颜色值按照像素点的顺序保存在 color buffer 中,就形成了一张完整的 color buffer。绘制 buffer 还有一块 depth buffer,depth buffer 也按照同样的方法,按照顺序保存了所有像素点的 depth 值;以及一块 stencil buffer,同理可知,stencil buffer 也是按照顺序保存了所有像素点的 stencil 值。

>EGL生成context，用来保存OpenGL的状态

EGL 还会根据格式生成一块 context,context 也是一块 buffer。我们知道 OpenGL ES 是状态集,那么在绘制中会牵扯到各种各样的状态,这些状态全部都有默认值,可以通过 OpenGL ES 对这些状态进行改变。这些状态值就会保存在 context 中。比如 OpenGL ES 所用到的混合模式、纹理图片、program 还有各种 BO 等信息。

当然 EGL 可以创建多个 surface 和 context,每个 surface 在创建的时候就是 包含了对应的绘制 buffer,每个 context 创建的时候内部都是默认值。然后我们可以根据自己的需要选择启动任意一套 surface 和 context,然后对选中的 surface 和 context 进行操作。一个进程同一时间只能启动有相同格式的一块 surface 和一块对应于 OpenGL ES 的 context,一块 context 同时也只能被一个进程启动。

# 三、Shader

## Shader 输入输出
Vertex Shader 输入顶点信息，输出有两个，必须输出的是该顶点在屏幕上的坐标信息，可选输出是该顶点的其他信息如颜色、纹理等，Vertex Shader一次只能操作一个顶点。输出体现在gl_Position

Fragment shader 的输入是屏幕上像素点的信息(坐标以及坐标对应的颜色，这里的像素点应该是光栅化之后的像素点?); fs/ps 不能改变像素点的位置，在操作像素点的时候 也不能访问旁边的像素点；输出是每个像素点的颜色，输出值用来更新buffer中的color buffer 或其他buffer。输出体现在gl_Position

# 四、GLSL
## 变量

### vector
vector 就是把同一个数据类型的多个值保存在一起，不带前缀的表示的是float
bvec2是用于将两个 bool 类型的值保存在了一起;ivec2、ivec3、ivec4 分别用于将两个 int 类型的值保存在一起,三个 int 类型的值保存在一起,和四个 int 类型的值保存在一起

vec2、3、4 的变量类型,然后将这些变量直接保存到 GPU 中对应硬件上,通过 GPU 的对应模块,一次运算可以得到之前 2 次 3 次 4 次或者更多次运算的结果,这样从带宽、运算效率和功耗上,都会得到大大的优化,所以定义这种变量非常有必要。目前基本上所有 GPU 都已经支持了这种 vec2、3、4 变量类型的运算

### 构造函数
bool(float) // converts a float value to a Boolean
int(bool) // converts a Boolean value to an int
float(int) // converts an integer value to a float

vec3(float) // initializes each component of with the float
vec3(float, vec2) // vec3.x = float, vec3.y = vec2.x, vec3.z = vec2.y

### mat
mat 是矩阵。如 mat2 和 mat3,分别是用于保存 2*2 个 float 类型的变量以及 3*3 个 float 类型的变量。Mat 只支持 float 类型,并不支持 bool 和 int,从这也可以看出 shader 中 float 类型是多么的重要

在硬件中,mat 变量是以列进行保存的

## 修饰符
### 存储修饰符
OpenGL ES、VS、PS可以看做三个空间，OpenGL ES需要向VS和PS传递数据，VS需要向PS传递数据。通过存储修饰符来区分作用的空间

#### < none: default >
只限于当前空间

#### const
当前空间的常量

#### attribute
attribute用于OpenGLES向VS传输坐标和颜色信息的。
OpenGL ES 可以通过 API 得到指定 VS 中某个 attribute 的位置,然后通过这个位置以及另外一个 API, 将数据传输到 VS 中。
attribute 修饰符只能修饰 float、vec2、vec3、vec4、mat2、mat3、mat4 类型的变量,可以看出这些全部都是只包含 float 类型变量的变量。

#### uniform
OpenGL ES向VS和PS传递矩阵、贴图等信息。
uniform 修饰符修饰的变量,可以是任何类型,甚至是 array 和 struct。

#### varying
varying 用于VS向PS传递数据

在 GLSL 中,唯一的共享全局就是 uniform。 varying 不被认为是共享全局的,因为它必须在 VS 和 PS 中同时定义,并且通过 VS 传给光珊化,再传给 PS

### 参数修饰符
#### < none: default > in
在函数中,如果一个参数是使用 in 修饰,而且没有被 const 修饰,那么它在函数中也可以被修改,但是其实修改的是函数中的那个变量的副本,并非传入的那个函数,所以在函数之外,这个参数的值是不变的。

#### out
函数的参数在传入的时候没有被初始化,然后应该在函数中进行赋值,然后在函数外,也就是在调用函数的代码块中被使用。

#### Inout
函数的参数被传入,然后在函数中再次被进行更新赋值,然后在函数外,也会被使用。inout 变量不能被 const 修饰。

## 内置变量
### gl_position
变量 gl_position 只存在于 VS 中,属于 VS 中的内置变量。用法是在 VS 中,需要将顶点坐标写入这个变量

### gl_PointSize
变量 gl_PointSize,也是只存在于 VS 中。属于 VS 的内置变量,用于说明点的尺寸,这个尺寸的单位是像素,比如把这个变量设置为 4,那么就代表一个 2*2 的像素方块是一个点

### gl_FragColor gl_FragData
对 gl_FragColor 进行赋值,顾名思义就是写入该像素点的颜色,在 OpenGL ES 的固定管线中,如果在 PS 之后对像素颜色进行读取,那么获取到的就是 PS 中 gl_FragColor 的值。如果在 PS 中没有对 gl_FragColor 进行赋值,那么像素颜色就是 undefine

# 五、Shader的绑定
经历流程：
创建shader，注入源码，compile源码；
创建program，attach shader，link program、use program

虽然步骤比较多，但都是程式化的，封装好后可以重复使用


# 六、传入绘制信息
绘制过程开始前，需要由CPU通过OpenGL ES向GPU传入绘制信息，如顶点左边和顶点颜色。

绘制信息可以由CPU中的变量逐个赋值给GPU中的变量，但是这样需要多次操作耗时费力，因为更好的办法是创建一个buffer 将CPU中的变量打包一次性传入GPU。

### 大致流程
产生buffer name，生成buffer object 并设定为GPU的当前buffer(bind)，给buffer 传递数据

attribute/uniform 变量的操作：获取location， 按需enable，赋值

绘制准备：设置viewPort， 清除绘制buffer

开始绘制

### 常用API

#### void glGenBuffers(GLsizei n, GLuint * buffers);
第一个输入参数的意思是该 API 会生成 n 个 buffer object name; 第二个输入参数用于保存被创建的 buffer object name。这些 buffer object name 其实也就是一些数字,而且假如一次性生成多个 buffer object name,那么它们没有必要必须是连续的数字

这一步其实只是创建了一些 buffer object name,而没有真正的创建 buffer object。而只有在这些 buffer object name 被 glBindBuffer 进行 bind 之后, 才会真正的创建对应的 buffer object。

#### void glBindBuffer(GLenum target, GLuint buffer);
buffer object 也是分类型的, 在 OpenGL ES2.0 中,buffer object 分为 VBO vertex buffer object 和 IBO index buffer object 两种。那么在这里,第一个输入参数必须是 GL_ARRAY_BUFFER 或者 GL_ELEMENT_ARRAY_BUFFER 。 其 中 GL_ARRAY_BUFFER 对应的是 VBO , GL_ELEMENT_ARRAY_BUFFER 对应的是 IBO。如果传入其他的参数,就会报 INVALID_ENUM 的错误。第二个输入参数为刚才 glGenBuffers 得到的 buffer object name。

这个函数没有输出参数,假如传入的 buffer 是刚被创建的 buffer object name,而且它还没有被创建和关联一个 buffer object,那么通过这个 API,就会生成一个制定类型的 buffer object,且与这个 buffer object name 关联在一起,之后指定某个 buffer object name 的时候,也就相当于指定这个 buffer object。新创建的 buffer object 是一个空间为 0,且初始状态为默认值的 buffer,初始状态为 GL_STATIC_DRAW。然后创建和关联完毕之后,也就会把这个 buffer object 当作是当前 GPU 所使用的 VBO 或者 IBO 了。如果传入的 buffer 已经有关联的 buffer object 了,那么只是把该 buffer object 指定为当前 GPU 所使用的 VBO 或者 IBO。然后 GPU 之前使用的 VBO 或者 IBO 就不再是处于被使用状态了

#### void glBufferData(GLenum target, GLsizeiptr size, const GLvoid * data, GLenum usage);

这个 API 就是通过 OpenGL ES,把 CPU 端保存的数据传递给 GPU 端, 保存在指定的 buffer object 中。
第一个输入参数的意思是指定 buffer object 的类型,可以是 GL_ARRAY_BUFFER 或者 GL_ELEMENT_ARRAY_BUFFER,
第二个和第三个输入参数的意思是:data 是 CPU 中一块指向保存实际数据的内存,而 size 为 data 以机器单元为单位的大小,size 不能为负,否则会报 INVALID_VALUE 的错误。


#### void glBindAttribLocation(GLuint program, GLuint index, const GLchar *name);
手动给VS中的 attribute 指定一个 location。至于是什么含义 什么作用 没有太明白
 attribute 必定是有一个 location，可以手动指定 也可由GPU设定。

#### GLint glGetAttribLocation(GLuint program, const GLchar*name);

OpenGL ES 去获取指定 VS 中某个 attribute 的位置。获取到这个位置之后,才可以通过 OpenGL ES 的其他 API 对 这个 attribute 进行操作。

第二个参数是一个字符串,用于保存 program 对应的 vertex shader 中的一个 attribute 的变量名。同样的,在这里暂时不会检测这个变量名是否真实有效,同时也不会检测是否以"gl_"作为前缀。所以在这里 name 只 需要是一个字符串即可。


#### void glEnableVertexAttribArray(GLuint index);
获取了 attribute 的 location 之后,在 OpenGL ES 以及 GPU 真正使用这个 attribute 之前,还需要通过 glEnableVertexAttribArray 这个 API,对这个 attribute 进行 enable。如果不 enable 的话,这个 attribute 的值无法被访问,比如无法通过 OpenGL ES 给这个 Attribute 赋值。更严重的是,如果不 enable 的话,由于 attribute 的值无法访问,GPU 甚至在通过 glDrawArray 或者 glDrawElement 这 2 个 API 进行绘制的时候都无法使用这个 attribute。

#### void glVertexAttribPointer(GLuint index, GLint size, GLenum type, GLboolean normalized, GLsizei stride, const GLvoid * pointer);

刚才做了那么多准备工作,获取到 attribute 的 location,然后 enable attribute, 目的就是往 attribute 传值。而最主要的传值 API 就是 glVertexAttribPoint,用处是 从 OpenGL ES 向 VS 中传输数据。在准备通过这个 API 传值之前,那些实际的值可能存放在 CPU 中,比如以一个指针或者数据的形式存放着,也有可能存放在 GPU 端,通过刚才创建并赋值了的 buffer object 保存着。不管存放在哪里,都可以通过这个 API 给 attribute 赋值。然后被赋值后的 attribute 就代表着若干个顶点的坐标或者颜色等等其他信息。

第一个参数是 attribute 的 location
第二个参数是 每个顶点参数的个数
第三个参数是 约定参数的数据类型，一般是GL_FLOAT
第四个参数是 是否使用归一化坐标，归一化就是带符号的值转化为(-1,1), 不带符号的值转化为(0,1)。
第五个参数是 是步长，即顶点之间间隔多少个数据，可默认为0 根据size来读取
第六个参数是 实际存放数据的指针地址。

#### Uniform的赋值
GLint glGetUniformLocation(GLuint program, const GLchar *name);
获取变量的location

void glUniform*iv(GLint location, GLsizei count, const GLint *value);
给变量赋值，有三种变体

第一种是直接以值的形式把数据传递给 Uniform,比如 glUniform1f, glUniform4f,glUniform4i 等。这个类型的 API 主要是用于当 shader 中的 uniform 为 float、int、vec 类型,且不是 array 的情况,给 uniform 赋值的。

第二个参数和第三个参数的意思是,count 代表将要改变指定的这个 uniform 数组一共由几个数组元素组成,可以是把数组全部赋值,或者部分赋值,而 value 就是指向实际存放要赋予给 uniform 的值的地址。

第三种是以指针的形式把数据传给 uniform,比如 glUniformMatrix2fv、 glUniformMatrix4fv。它和第二种 API 的区别在于这个类型的 API 主要用于当 shader 中的 uniform 为 matrix 类型,它也支持 uniform 为 array。

相比于Attribute 类型变量，uniform 不需要enable？

#### void glViewport(GLint x, GLint y, GLsizei width, GLsizei height);
我们在EGL中，通过eglCreateWindowSurface的时候，创建了一块绘制buffer，这块buffer的大小为屏幕分辨率的大小。然而虽然这块buffer的大小已经确定了，但是并不代表我们使用这块buffer进行绘制的时候，一定要完全按照这个buffer的大小去绘制。

glViewPort这个API，就是用于设定绘制区域的，绘制区域不同，直接导致了绘制的位置以及绘制图片的大小。

#### void glClearColor(GLclampf red, GLclampf green, GLclampf blue, GLclampf alpha);

glClear，用于清理绘制buffer。因为我们通过egl创建的绘制buffer，其实也就是一块内存，但是这个内存在刚被创建好的时候，并不会被初始化，那么根据平台不同，里面保存的东西可能不同。

所以我们先要把buffer涂上底色，而glClearColor这个API，就是设定一种颜色，作为清理绘制buffer所使用的颜色。 注意这个API只是设定color

#### void glClear(GLbitfield mask);

用于使用预先设定的值去清理绘制buffer，比如我们想要清理绘制buffer的颜色，那么通过刚才的glclearcolor API，我们已经确定好一种颜色了，然后通过这个API，就可以调用GPU，对绘制buffer的颜色根据刚才设定的颜色进行清理。

#### void glDrawArrays(GLenum mode, GLint first, GLsizei count);

第一个参数 绘制模式，Points, Line, Triple
第二和第三个参数，从first开始的count 参与绘制

#### void glDrawElements(GLenum mode, GLsizei count, GLenum type, const GLvoid * indices);
类似于 glDrawArrays, 通过indices指定不连续的点参与绘制

# 七、纹理



texture object与buffer object类似。都是GPU中的一块buffer。我们也知道buffer object有glGenBuffers、glBindBuffer、glBufferData、glBufferSubData、glDeleteBuffers五大API，分别用于buffer object的创建，赋值和删除。同样的，texture object也有同样的五大API，分别是glGenTextures、glBindTexture、glTexImage2D、glTexSubImage2D和glDeleteTexture，功能与刚才buffer object的5个API基本一样。

### 常用API

#### void glGenTextures(GLsizei n, GLuint * textures);
生成纹理的name, 并将其标记为已使用

#### void glBindTexture(GLenum target, GLuint texture);
创建纹理对象。

第一个参数 是纹理的类型，在OpenGL ES2.0中，分为2D texture和CUBEMAP texture 两种。2D texture比较容易理解，就是一张2D的纹理图片，CUBEMAP的texture顾名思义，是用于组成Cube的texture，我们知道cube是立方体的意思，那么立方体有6个面，所以CUBEMAP texture是由6张2D texture组成的

第二个输入参数为刚才glGenTextures得到的texture object name

texture object是一个容器，它持有该纹理被使用时所需要用到的所有数据，这些数据包括图像像素数据、filter模式、wrapmode等。

创建和关联完毕之后，就会把这个texture object当作是当前GPU所使用的2D texture或者cubemap texture。

纹理单元就好比一个容器，一个GPU中最多可以有8个纹理单元，具体有几个，需要看GPU的实现。纹理单元是用于盛放纹理的，一个纹理单元中同一个类型的纹理最多只能有一个，我们刚才已经知道了OpenGL ES中只有两种类型的纹理，2D texture和cubemap texture。所以一个纹理单元中最多只能有2个纹理。

而GPU中同一时间一个thread的一个context中只能有一个纹理单元是处于active状态，而一个纹理单元中同一时间同一个类型只能有一个texture，所以，我们我们创建和关联一个texture，只是将该纹理关联到了目前active的那个纹理单元，然而刚好，该纹理单元是处于被GPU使用状态，所以才使得该texture是当前GPU所使用的2D texture或者cubemap texture。假设一种情况，我们这个texture依然属于这个纹理单元，没有被别的texture替换，但是这个纹理单元，不再被GPU使用了，那么该texture也就不再是当前GPU所使用的了。

>ps:纹理属于纹理单元，一个GPU最多有8个纹理单元；每个纹理单元同类型的纹理只能有一个；一个线程的一个context只能有一个纹理单元是active状态。

buffer object直接被GPU所使用，可以直接通过glBindBuffer提交给GPU。但是**texture object则多了一层，texture object被纹理单元使用，而纹理单元被GPU使用，所以glBindTexture，只是将texture提交给了纹理单元**。默认的纹理单元是GL_TEXTURE0


**我们通过glGenTextures创建一些texture object name。然后通过glBindTexture，给texture object name创建和关联一个texture object，同时，通过这个API，还将这个texture object放入了当前被使用的纹理单元中，由于这个纹理单元正在被GPU使用，所以这个texture也就成了GPU所使用的2D texture或者cubemap texture，虽然GPU中可以存放大量的纹理单元，每个纹理单元又都包含着纹理，而且在纹理单元这些容器外面还有很多游离的纹理，但是同一时间一个thread的一个context中只能有一个纹理单元被使用，以及只能有一个2D texture和一个cubemap texture是被使用着的。之后关于texture的操作，比如查询texture的状态等，对texture进行赋值，我们就会直接操作2D texture或者cubemap texture，而不会在使用texture object name了。所以，如果想使用某个texture object，我们就需要先通过glActiveTexture active一个纹理单元，然后通过glBindTexture将texture放入该纹理单元，将该texture设置为GPU当前的2D texture或者cubemap texture，然后才能对该texture object进行操作。**

一个texture object可以放在多个纹理单元中，而任何对该texture object的操作，都会影响到所有与其关联的纹理单元。比如删除一个2D的texture object，而这个texture object原本可能被放入0、1、4这3个纹理单元中。那么就相当于把这个纹理从这三个纹理单元中都取出来，也就相当于先把这三个纹理单元分别进行了active，然后进行了glBindTexture（GL_TEXTURE_2D，0）的操作。再比如对这个2D texture object进行修改，那么在使用这三个纹理单元中的GL_TEXTURE_2D的时候，使用到的都是修改之后的值。

#### void glActiveTexture(GLenum texture);
GPU中同一时间一个thread的一个context中只能有一个纹理单元是处于被使用状态，所以想要将所有纹理单元中都放入texture，就需要不停的切换active texture。那么glActiveTexture这个API，就是用于将**某个指定的纹理单元设置为被使用状态**。

#### void glTexImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const GLvoid * data);

将CPU中的像素数据传递到GPU中生成纹理，一旦该命令被执行，会立即将图像像素数据从CPU传输到GPU的内存中，后续对客户端数据的修改不会影响服务器中的texture object相关信息。所以在这个API执行之后，客户端中的图像数据就可以被删掉了。

第一个参数，2D Texture 或者 cubemap texture的一个面
第二个参数，level 纹理的层级 ，暂时不理解是什么意思
第三个参数，是用于指定纹理在GPU端的格式，只能是GL_ALPHA, GL_LUMINANCE, GL_LUMINANCE_ALPHA, GL_RGB, GL_RGBA。GL_ALPHA指的是每个像素点只有alpha通道，相当于RGB通道全为0。GL_LUMINANCE指的是每个像素点只有一个luminance值，相当于RGB的值全为luminance的值，alpha为1。GL_LUMINANCE_ALPHA指的是每个像素点有一个luminance值和一个alpha值，相当于RGB的值全为luminance的值，alpha值保持不变。GL_RGB指的是每个像素点有一个red、一个green值和一个blue值，相当于RGB的值保持不变，alpha为1。GL_RGBA指的是每个像素点有一个red、一个green值、一个blue值和一个alpha值，相当于RGBA的值都保持不变。
第四、五个参数，原始图片的宽和高，也是新生成纹理的宽和高。
第六个参数 必定为0
第七、八个参数 ，像素数据在CPU端的格式
第九个参数，CPU中内存数据的指针

对应的有`void glTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, const GLvoid * data);
`只传递部分数据到texture

先通过glGenTextures给生成一个新的texture object name。然后选择一个纹理单元，把这个texture object name生成纹理并绑定到这个纹理单元上。所以通过glActiveTexture把纹理单元enable，然后再通过glBindTexture把这个texture与GL_TEXTURE_2D绑定，我们知道这个texture object name是刚创建的，所以在执行这个命令的时候，我们知道，会先生成一个2D的texture object，然后把这个texture object放入刚才enable的那个纹理单元中。下面再通过glTexParameter对纹理设置参数。之后会使用对应的API去生成纹理内容，比如通过glTexImage2D，传入了target GL_TEXTURE_2D，传入了第几层mipmap，传入了准备好的internalformat、宽、高、format、type和data信息。纹理图片经历了解包、归一划、转换为RGB格式、归一划的过程，存储到了GPU中，在内存中，需要按照UNPACK_ALIGNMENT对齐。当CPU的纹理图片unpack到了GPU，开发者可以把CPU端的纹理图片删除。如果数据来源自CPU的JPG、PNG图片，这些格式图片不包含mipmap信息，而如果来自于pvr、etc之类的用于生成压缩纹理的原始图片，才可能会有mipmap信息。如果需要的话，再通过glHint设置生成mipmap的算法，然后通过glGenerateMipmap生成mipmap信息。这样的话一张纹理就生成了。当纹理使用完毕后，就要通过glDeleteTextures这个API把原来对应的纹理删除，并且把texture object name reset为0。

### 纹理优化之纹理格式
纹理占用内存的计算公式：纹理宽＊纹理高＊bpp，bpp为每个像素所占的位数 即 bits per pixel。

纹理宽高即图片的宽和高，bbp根据不同的格式有：GL_RGBA8888和GL_RGBA4444的bpp分别为32和16，那么使用16位纹理格式比32位的纹理格式要少占用一半的内存；再比如一些用于背景等非透明图象的纹理，就可以使用比如GL_RGB565之类的格式，由于不需要alpha通道，也就不使用带alpha通道的纹理格式，也能大大减少对内存的占用。还有对应alpha通道要求简单的图像，则可以使用GL_RGBA5551的纹理格式。


# 八、FBO
这里把EGL创建的framebuffer称为framebuffer，也叫做window-system-provided framebuffer，**关键在于它不能被OpenGL ES操作**;把OpenGL ES创建的FBO称为FBO，也叫做application-created framebuffer，其实它们构造是一样的，只是默认情况下，OpenGL ES使用的是window-system-provided framebuffer，而且通过EGL swap到屏幕上的时候，只能swap framebuffer）

通过之前的内容，知道了OpenGL ES2.0就是把内容绘制到EGL创建的framebuffer上，然后swap到屏幕上。但是有了FBO后，也可以先把内容绘制到FBO上，然后再搞到framebuffer上，最后再swap到屏幕上。

window-system-provided framebuffer 和application-created framebuffer的最主要的区别是：
1. FBO的attachment可以修改。在OpenGL ES2.0中FBO只能有一个color attachment挂载点GL_COLOR_ATTACHMENT0、一个depth attachment挂载点GL_DEPTH_ATTACHMENT、一个stencil attachment挂载点GL_STENCIL_ATTACHMENT，而这三个挂载点初始都为GL_NONE，需要通过API glFramebufferRenderbuffer和glFramebufferTexture2D手动挂载。挂载到上面的RBO和texture也是由OpenGL ES来创建和控制。
2. 无论读取还是写入，像素所有权测试总是通过。
3. FBO的buffer无法像framebuffer那样可以被swap到屏幕上，所以OpenGL ES针对这种绘制叫做off-screen rendering。
4.没有multisample buffer，所以针对FBO的 GL_SAMPLES 和GL_SAMPLE_BUFFERS 均为0。




### 常用API
#### void glGenFramebuffers(GLsizei n, GLuint * framebuffers);

#### void glBindFramebuffer(GLenum target, GLuint framebuffer);
通过这个 API,还将参数 framebuffer 对应的 framebuffer object 设置为目前 GPU 所使用的 framebuffer。

一个FBO有一个color attachment挂载点、一个depth attachment挂载点、一个stencil attachment挂载点。然后创建和关联完毕之后,也就会把这个 framebuffer object 当作是当前 GPU 所使用的 framebuffer 了，也就是说OpenGL ES再次绘制的时候，将不再绘制到 window-system-provided framebuffer，而是绘制到这个FBO上了

#### void glGenRenderbuffers(GLsizei n, GLuint * renderbuffers);

renderbuffer就是FBO上关联的一块buffer（texture也可以）。renderbuffer是由OpenGL ES创建和管理的，所以可以随意的将其与FBO进行attach和detach，甚至可以将其与多个FBO绑定，这样可以避免了数据copy以及减少了内存浪费。这一点window-system-provided framebuffer就做不到。

renderbuffer被attach到FBO上后，当该FBO active后，这块renderbuffer就被作为OpenGL ES实际绘制和读取的目标。

#### glBindRenderbuffer(GLenum target, GLuint renderbuffer);

创建和关联完毕之后,也就会把这个 renderbuffer object 当作是当前 GPU 所使用的 RBO 了。如果传入的 renderbuffer 已经有关联的 renderbuffer object 了,那么只是把该 renderbuffer object 指定为当前 GPU 所使用的 renderbuffer。然后 GPU 之前使用的 RBO 就不再是处于被使用状态了。

#### void glRenderbufferStorage(GLenum target, GLenum internalformat, GLsizei width, GLsizei height);

通过上面2个API创建了一个size为0的RBO，虽然这个RBO可以attach到FBO上，但是依然无法被使用，因为绘制buffer尺寸怎么可以只为0呢，所以就通过glRenderbufferStorage这个API给RBO创建、初始化存储空间。

#### void glFramebufferRenderbuffer(GLenum target, GLenum attachment, GLenum renderbuffertarget, GLuint renderbuffer);

通过这个API可以将指定的RBO关联到GPU当前的FBO上。



